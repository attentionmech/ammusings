0101 - January 3rd

[1]

*Can ai safety really be done without loopholes*

Is there any real world system which don't have loopholes? whether it's personal security, or systems security or industrial security - we were never able to build systems which can effectively be fullproof from holes. So what makes us believe that fragmented systems can be like kept safe and without loop holes?
